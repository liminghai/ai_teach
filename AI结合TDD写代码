# AI结合TDD写代码

# 背景

测试驱动开发，先产出可测的测试场景，再补齐测试细节，最后生成测试代码与实现。

# 核心思想

TDD的核心在于先测试，后实现。通过可复用的prompt模板，我们可以将复杂的需求分解为可测试的场景，再逐步细化到具体的测试用例和实现代码。

prompt模板包含：

1.  测试场景prompt：从功能需求提炼可测的场景与数据。
    
2.  测试细节prompt：基于需求与测试场景，补齐被测对象与断言细节。
    
3.  测试与实现prompt：在规范约束下，生成测试代码与功能实现。
    

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/pLdn55Xap7K9jno8/img/84f92581-a276-4f6e-ba5f-d1cd26b985f6.png)

# prompt模板体系

## 测试场景prompt

### 作用

把\[功能需求\]转化为\[测试场景\]与\[测试数据\]。

### 流程

输入：功能需求

输出：测试场景（含简要数据与预期结果）

### 模板

```json
功能需求
====
{requirement}

任务
====
1. 请根据上面的功能需求，列出需要测试的场景。描述场景，并给出相关的测试数据。保持简洁。
2. 测试用例输出为markdown格式，保存到私有知识库目录下

样例
====
需求为 实现一个命令行解析工具
输出：

1. 布尔标志测试
- 场景描述：测试解析程序是否可以正确处理布尔标志。
- 测试数据：'-l -p 8080'
- 预期结果：'{"l": true}'
```

备注：模板中的样例作为few shots example，让LLM的输出更加稳定。

### 人工review

**在得到测试场景后，必须先进行人工review**

*   检查测试覆盖面是否完整
    
*   验证边界条件是否合理
    
*   确认测试数据的合理性
    

**为什么需要人工review？**

**”以自然语言产生的测试/任务列表，我们更容易发现错误，并提出反馈。而以代码形式表示的功能代码，我们却很难在第一时间发现错误。因此我们就更需要在更早的时候提出反馈，避免错误的累积。“ -- 徐昊《AI时代的软件工程》**

### 使用示例

#### 功能需求

手动整理一下PRD的功能需求，降低复杂度。

```json
保护用户昵称隐私的java实现，规则如下：
当昵称长度小于3个字符时，仅显示首字母并用星号代替其余部分；
当昵称长度大于2个字符时，首尾字符保留，中间字符用星号替代。
```

#### 提示词

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/pLdn55Xap7K9jno8/img/6d850252-271d-40c5-89f5-39e3bbfef631.png)

## 测试细节prompt

### 作用

在已有\[需求+测试场景\]的基础上，确定被测对象（SUT）、核心方法、入参与返回、验证方式等\[测试细节\]。

### 模板

```json
功能需求
====
{requirement}

测试场景
====
{test_scenario}

任务
====

请根据需求和测试场景补充下面的测试细节：

- 被测试的类叫{SUT Class name}。它的构造函数接受{which dependency}；
- {SUT Class name}的{core method name}方法返回{return}作为结果，接受{parameter}作为参数；
- 验证时，通过{validation method}，完成验证。

样例
====

需求为 实现一个命令行解析工具。
输出：

- 被测试的类叫ArgumentParser。它的构造函数接受Map作为参数配置；
- ArgumentParser的parse方法返回Map作为解析结果，接受args("-l -p 8080")作为参数；
- 验证时，通过从Map中获取对应参数值，完成验证。
```

### 使用示例

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/pLdn55Xap7K9jno8/img/3dfd5d7c-bea2-4471-9125-27f5ccc1a8c5.png)

## 测试与实现prompt

### 作用

在遵循既定测试规范的前提下，基于\[需求 + 测试场景 + 测试细节\] 生成 \[测试代码\] 与 \[功能实现\]。

### 模板

```json
功能需求
====
{requirement}

测试场景
====
{test_scenario}

测试细节
====
{test_scenario_detail}

任务
====
请根据 [功能需求] 、[测试场景] 和 [测试细节] 生成测试代码 和 代码实现。

测试细节：
{test_detail}

测试要求（测试Rule）
- 每个厂家对应一个测试方法。测试方法内部加中文注释标明测试场景。
- 测试方法命名必须采用`should_xxx_when/if_condition`格式，
  例如: should_return_empty_when_user_is_not_active。
- 必须使用JUnit5 + Mockito + AssertJ组合，不使用 @Mock @InjectMocks annotation 来注入，
  使用构造函数或者直接设置字段来注入。
- 测试方法必须自解释，禁止添加不必要的注释。
- 提取通用断言逻辑，优先创建DSL。
- 使用 @Nested 来分类各个测试。
- 采用 ParameterizedTest CsvSource MethodSource 等Junit的技巧，保持单元测试的简洁。
- 使用 真实对象 或者 使用Mockito 来模拟外部依赖，或者使用 Fake 来模拟外部依赖。
- 应该大量使用 state verification，尽量少用 behavior verification。
- 应该将时间、random等作为参数传入，从而保证测试的稳定性
  （constructor 注入 SupplierLocalDateTime/SupplierLocalDate）。
- 对于测试数据中有 时间戳，应该使用 LocalDateTime再转换成时间戳，增加测试的可读性。
- 对于检查类方法，不仅需要检查true或者false，还要检查error code(enum)是对的。
- 测试运行规范：1. 使用mvn进行完整项目构建（首次运行必需），因为这是个多module的系统；2. 运行指定模块的指定测试。

写代码时，必须遵守以下规则（代码实现规范）：
- 禁止直接使用`null`值，使用`Optional<T>`包装可能为空的对象。
- 禁止使用`else`分支，使用卫语句提前返回，或者提取方法（extract method）来避免使用`else`。
- 禁止使用传统`for`循环，使用`Stream API`进行集合处理。
- 禁止模糊缩写，使用意图明确的命名。
    - 对于`Map`使用`xx2yy`格式，例如：`Map<Long, Account> userId2Account`
    - 对于`List`，使用`xx(s)`的格式，例如：`List<String> configuredSegments`
- 每个方法不超过7行代码，强制拆分长方法为小方法。
- 避免无意义的注释，尽量使用变量名/方法名来解释。
- 对于复杂方法，若无法用变量名/方法名清晰表达，则使用中文注释。
- 参数应尽量避免使用`Optional`类型。
- 参数不合法时，直接抛出 `IllegalArgumentException`异常。
- 对于 `xxxId` 类型的参数，应使用 `Long` 类型而非 `int` 或 `String` 类型，例如 `Long userId`。
- 对于检查类方法，返回值需要包含错误信息（error message）和错误码（error code）。
- 应使用枚举（`Enum`）的地方就要使用，例如 `rewardType`。
```

### 使用示例

![image](https://alidocs.oss-cn-zhangjiakou.aliyuncs.com/res/pLdn55Xap7K9jno8/img/7409dc46-a9bf-498f-8498-fba16aef8ccc.png)

# 快速上手流程

1.  **粘贴功能需求**到测试场景prompt
    
2.  将**功能需求 + 测试场景** 交给测试细节prompt
    
3.  将**功能需求 + 测试场景 + 测试细节** 交给Cursor/Qwcoder/Claude Code/...，产出测试代码+功能实现。
    

# 未来展望

**自动化流程优化**：当前流程需要用户手动复制粘贴多个阶段的prompt，未来可以考虑通过多个子代理（subAgent）协同工作，由主代理（hostAgent）引导用户完成整个TDD流程，提升用户体验。
